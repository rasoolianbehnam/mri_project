{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_4/concat:0' shape=(?, 32, 32, 256) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape=[32, 32, 192])\n",
    "def inception_module(input_, n_features=[96, 16, 64, 128, 32, 32]):\n",
    "    d11, d12, d20, d21, d22, d23 = n_features\n",
    "    c11 = keras.layers.Conv2D(d11, (1, 1), padding='same', activation='relu')(input_)\n",
    "    c12 = keras.layers.Conv2D(d12, (1, 1), padding='same', activation='relu')(input_)\n",
    "    m11 = keras.layers.MaxPool2D((3, 3), strides=1, padding='same')(input_)\n",
    "\n",
    "\n",
    "    c20 = keras.layers.Conv2D(d20, (1, 1), padding='same', activation='relu')(input_)\n",
    "    c21 = keras.layers.Conv2D(d21, (3, 3), padding='same', activation='relu')(c11)\n",
    "    c22 = keras.layers.Conv2D(d22, (5, 5), padding='same', activation='relu')(c12)\n",
    "    c23 = keras.layers.Conv2D(d23, (1, 1), padding='same', activation='relu')(m11)\n",
    "\n",
    "    return keras.layers.concatenate([c20, c21, c22, c23])\n",
    "inception_module(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_unit(input_, kernel_size=(3, 3), strides=1):\n",
    "    n_features = input_.shape[-1]\n",
    "    c10 = keras.layers.Conv2D(n_features, kernel_size, strides=strides, padding='same')(input_)\n",
    "    c11 = keras.layers.BatchNormalization()(c10)\n",
    "    c12 = keras.layers.ReLU()(c11)\n",
    "    c20 = keras.layers.Conv2D(n_features, kernel_size, padding='same')(c12)\n",
    "    c21 = keras.layers.BatchNormalization()(c20)\n",
    "    c22 = keras.layers.ReLU()(c21)\n",
    "    if strides > 1:\n",
    "        input_ = keras.layers.Conv2D(n_features, (1, 1), strides)(input_)\n",
    "        input_ = keras.layers.BatchNormalization()(input_)\n",
    "    return keras.layers.ReLU()(c22+input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 're_lu_32/Relu:0' shape=(?, 128, 128, 3) dtype=float32>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_unit(input_, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, kernel_size=3, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(filters, kernel_size, \n",
    "                                strides=strides, padding='same', use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters, kernel_size, \n",
    "                                strides=1, padding='same', use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "        ]\n",
    "        self.skip_layers = [\n",
    "            keras.layers.Conv2D(filters, 1, strides, use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "        ]\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        Z_skip = inputs\n",
    "        if self.strides > 1 or self.filters != Z_skip.shape[-1]:\n",
    "            for layer in self.skip_layers:\n",
    "                Z_skip = layer(Z_skip)\n",
    "        return self.activation(Z + Z_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalMaxPooling2D, BatchNormalization, ReLU, Flatten, Dense\n",
    "input_ = keras.layers.Input(shape=[224, 224, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Conv2D(64, 7, strides=2, padding='same', input_shape=[256, 256, 3], use_bias=False),\n",
    "    BatchNormalization(), ReLU(),\n",
    "    MaxPool2D((3, 3), strides=2, padding='same'),\n",
    "    ResidualUnit(64),\n",
    "    ResidualUnit(64),\n",
    "    ResidualUnit(64),\n",
    "    ResidualUnit(64),\n",
    "    ResidualUnit(128, 2),\n",
    "    ResidualUnit(128),\n",
    "    ResidualUnit(128),\n",
    "    ResidualUnit(128),\n",
    "    GlobalMaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform([2, 7, 7, 15])\n",
    "filters = tf.random.uniform(shape=[7, 7, 15, 10])\n",
    "out = tf.nn.conv2d(x, filters, strides=1, padding='VALID')\n",
    "out2 = tf.matmul(Flatten()(x),  tf.reshape(filters, [-1, 10]))\n",
    "with tf.Session() as sess:\n",
    "    x1, x2 = sess.run([out, out2])\n",
    "np.allclose(x1.reshape(-1, 10), x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting FCN to Dense:\n",
    "Note that the output dimensions should be equal to kernel size\n",
    "`filter`: a tensor of shape `[k1, k2, f1, f2]`\n",
    "`weights = tf.reshape(filter, [-1, f2])`\n",
    "```[?, k1, k2, f] -> flatten -> Dense(weights)``` is equivalent to ```[?, k1, k2, f] -> tf.nn.Conv2d(f2, (k1, k2), padding='valid')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Dense to FCN:\n",
    "- Dense: \n",
    "    - `weights` is a tensor of shape `[n*m*f, k]`\n",
    "    - `[?, n, m, f] -> flatten [, n*m*f] -> Dense(weights)`\n",
    "- FCN:\n",
    "    - `filter = tf.transpose(tf.reshape(weights, [f, n, m, k]), [1, 2, 0, 3])`\n",
    "    - `[?, n, m, f] -> tf.nn.Conv2d(filter, strides=1, padding=\"VALID\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorGpu4",
   "language": "python",
   "name": "tensorgpu4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
